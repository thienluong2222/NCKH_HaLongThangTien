import pandas as pd
import os
from pathlib import Path
import cv2
import numpy as np
from collections import Counter, defaultdict
import matplotlib.pyplot as plt
from ultralytics import YOLO

model_path = ''
csv_path = ''
video_path = ''
output_video_path = ''




class YOLOCSVPipeline:
    def __init__(self, model_path, csv_path):
        """
        Pipeline ƒë·ªÉ detect object b·∫±ng YOLO v√† map v·ªõi CSV

        Args:
            model_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn model YOLO
            csv_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file CSV mapping
        """
        self.model = YOLO(model_path)
        self.mapping_df = pd.read_csv(csv_path)

        # Chu·∫©n h√≥a t√™n c·ªôt
        self.mapping_df.columns = self.mapping_df.columns.str.strip()

        print(f"‚úÖ ƒê√£ load model: {model_path}")
        print(f"‚úÖ ƒê√£ load CSV: {csv_path}")
        print(f"üìä S·ªë d√≤ng trong CSV: {len(self.mapping_df)}")
        print(f"üìã C√°c c·ªôt: {list(self.mapping_df.columns)}")

    def predict_and_map(self, image_path, confidence_threshold=0.5, show_image=True):
        """
        Detect object v√† map v·ªõi CSV
        """
        # 1. YOLO Predict
        results = self.model.predict(image_path, verbose=False)

        detected_items = []  # L∆∞u c·∫£ class_name V√Ä confidence
        matched_results = []

        for result in results:
            if show_image:
                result.show()
            boxes = result.boxes

            if boxes is not None:
                for box in boxes:
                    confidence = float(box.conf)

                    # Ch·ªâ l·∫•y detection c√≥ confidence >= threshold
                    if confidence >= confidence_threshold:
                        class_id = int(box.cls)
                        class_name = result.names[class_id]

                        # ‚úÖ L∆∞u C·∫¢ class_name V√Ä confidence t∆∞∆°ng ·ª©ng
                        detected_items.append({
                            'class_name': class_name,
                            'confidence': confidence
                        })

        # 2. Map v·ªõi CSV
        for item in detected_items:
            detected_class = item['class_name']
            conf = item['confidence']  # ‚úÖ L·∫•y confidence t∆∞∆°ng ·ª©ng

            # T√¨m trong CSV (case-insensitive)
            matches = self.mapping_df[
                self.mapping_df['SubClass'].str.lower() == detected_class.lower()
            ]

            if not matches.empty:
                for _, row in matches.iterrows():
                    matched_results.append({
                        'detected_subclass': detected_class,
                        'mapped_subclass': row['SubClass'],
                        'class': row['Class'],
                        'text': row['Text'],
                        'confidence': conf  # ‚úÖ D√πng confidence ƒë√∫ng
                    })
            else:
                # Kh√¥ng t√¨m th·∫•y mapping
                matched_results.append({
                    'detected_subclass': detected_class,
                    'mapped_subclass': None,
                    'class': None,
                    'text': None,
                    'confidence': conf  # ‚úÖ D√πng confidence ƒë√∫ng
                })

        return matched_results

    def process_single_image(self, image_path, show_unmapped=False):
        """
        X·ª≠ l√Ω 1 ·∫£nh v√† hi·ªÉn th·ªã k·∫øt qu·∫£
        """
        print(f"\n{'='*60}")
        print(f"üñºÔ∏è  ƒêang x·ª≠ l√Ω: {os.path.basename(image_path)}")
        print(f"{'='*60}")

        results = self.predict_and_map(image_path)

        if not results:
            print("‚ùå Kh√¥ng ph√°t hi·ªán object n√†o!")
            return None

        print(f"\n‚úÖ Ph√°t hi·ªán {len(results)} object(s):\n")

        for i, result in enumerate(results, 1):
            if result['mapped_subclass'] is not None:
                print(f"{i}. üéØ Detected: {result['detected_subclass']}")
                print(f"   ‚îú‚îÄ SubClass: {result['mapped_subclass']}")
                print(f"   ‚îú‚îÄ Class: {result['class']}")
                print(f"   ‚îú‚îÄ Text: {result['text']}")
                print(f"   ‚îî‚îÄ Confidence: {result['confidence']:.2%}\n")
            elif show_unmapped:
                print(f"{i}. ‚ö†Ô∏è  Detected: {result['detected_subclass']}")
                print(f"   ‚îî‚îÄ Kh√¥ng t√¨m th·∫•y mapping trong CSV\n")

        return results

    def process_folder(self, image_folder, output_csv='results.csv',
                    confidence_threshold=0.5):
        """
        X·ª≠ l√Ω t·∫•t c·∫£ ·∫£nh trong th∆∞ m·ª•c
        """
        print(f"\n{'='*60}")
        print(f"üìÅ X·ª≠ l√Ω th∆∞ m·ª•c: {image_folder}")
        print(f"{'='*60}\n")

        # L·∫•y t·∫•t c·∫£ ·∫£nh
        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']
        image_files = []

        for ext in image_extensions:
            image_files.extend(Path(image_folder).glob(f'*{ext}'))
            image_files.extend(Path(image_folder).glob(f'*{ext.upper()}'))

        if not image_files:
            print("‚ùå Kh√¥ng t√¨m th·∫•y ·∫£nh n√†o!")
            return None

        print(f"T√¨m th·∫•y {len(image_files)} ·∫£nh\n")

        all_results = []

        for img_path in image_files:
            results = self.predict_and_map(str(img_path), confidence_threshold)

            for result in results:
                result['image'] = os.path.basename(str(img_path))
                all_results.append(result)

            print(f"‚úì {os.path.basename(str(img_path))}: {len(results)} detections")

        # T·∫°o DataFrame
        df = pd.DataFrame(all_results)

        # L·ªçc ch·ªâ l·∫•y k·∫øt qu·∫£ c√≥ mapping
        df_mapped = df[df['mapped_subclass'].notna()].copy()

        # S·∫Øp x·∫øp
        df_mapped = df_mapped.sort_values(['image', 'confidence'],
                                        ascending=[True, False])

        # L∆∞u file
        df_mapped.to_csv(output_csv, index=False, encoding='utf-8-sig')

        print(f"\n{'='*60}")
        print(f"‚úÖ Ho√†n th√†nh!")
        print(f"üìä T·ªïng detections: {len(all_results)}")
        print(f"‚úì C√≥ mapping: {len(df_mapped)}")
        print(f"‚úó Kh√¥ng mapping: {len(all_results) - len(df_mapped)}")
        print(f"üíæ ƒê√£ l∆∞u: {output_csv}")
        print(f"{'='*60}\n")

        # Th·ªëng k√™
        if not df_mapped.empty:
            print("üìà Top 10 Class ph·ªï bi·∫øn:")
            print(df_mapped['class'].value_counts().head(10))
            print("\nüìà Top 10 SubClass ph·ªï bi·∫øn:")
            print(df_mapped['mapped_subclass'].value_counts().head(10))

        return df_mapped

    def get_info_by_subclass(self, subclass_name):
        """
        Tra c·ª©u th√¥ng tin t·ª´ SubClass
        """
        matches = self.mapping_df[
            self.mapping_df['SubClass'].str.lower() == subclass_name.lower()
        ]

        if matches.empty:
            return None

        return matches[['Text', 'Class', 'SubClass']].to_dict('records')

    def draw_detections(self, frame, detections_data):
        """
        V·∫Ω bounding box v√† th√¥ng tin l√™n frame

        Args:
            frame: Frame c·∫ßn v·∫Ω
            detections_data: Danh s√°ch detection v·ªõi boxes v√† th√¥ng tin

        Returns:
            frame ƒë√£ ƒë∆∞·ª£c v·∫Ω
        """
        annotated_frame = frame.copy()

        for det in detections_data:
            # L·∫•y th√¥ng tin bounding box
            box = det['box']  # [x1, y1, x2, y2]
            confidence = det['confidence']
            label = det['label']

            # Chuy·ªÉn ƒë·ªïi t·ªça ƒë·ªô
            x1, y1, x2, y2 = map(int, box)

            # M√†u s·∫Øc (xanh l√° cho mapped, v√†ng cho unmapped)
            color = (0, 255, 0) if det.get('mapped', False) else (0, 255, 255)

            # V·∫Ω bounding box
            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, 2)

            # Chu·∫©n b·ªã text
            text = f"{label} {confidence:.2f}"

            # T√≠nh k√≠ch th∆∞·ªõc text
            font = cv2.FONT_HERSHEY_SIMPLEX
            font_scale = 0.6
            thickness = 2
            (text_width, text_height), baseline = cv2.getTextSize(
                text, font, font_scale, thickness
            )

            # V·∫Ω background cho text
            cv2.rectangle(
                annotated_frame,
                (x1, y1 - text_height - 10),
                (x1 + text_width, y1),
                color,
                -1
            )

            # V·∫Ω text
            cv2.putText(
                annotated_frame,
                text,
                (x1, y1 - 5),
                font,
                font_scale,
                (0, 0, 0),
                thickness
            )

            # V·∫Ω th√™m th√¥ng tin Class n·∫øu c√≥ mapping
            if det.get('mapped', False) and det.get('class_name'):
                class_text = f"{det['class_name']}"
                cv2.putText(
                    annotated_frame,
                    class_text,
                    (x1, y2 + 20),
                    font,
                    0.5,
                    color,
                    1
                )

        return annotated_frame

    def predict_and_map_with_boxes(self, frame, confidence_threshold=0.5):
        """
        Detect object, map v·ªõi CSV v√† tr·∫£ v·ªÅ c·∫£ th√¥ng tin boxes

        Args:
            frame: Frame ho·∫∑c ƒë∆∞·ªùng d·∫´n ·∫£nh
            confidence_threshold: Ng∆∞·ª°ng confidence

        Returns:
            List c√°c detection v·ªõi boxes v√† mapping info
        """
        # YOLO Predict
        results = self.model.predict(frame, verbose=False)

        detections_data = []

        for result in results:
            boxes = result.boxes

            if boxes is not None:
                for box in boxes:
                    confidence = float(box.conf)

                    if confidence >= confidence_threshold:
                        class_id = int(box.cls)
                        class_name = result.names[class_id]

                        # L·∫•y t·ªça ƒë·ªô bounding box
                        xyxy = box.xyxy[0].cpu().numpy()  # [x1, y1, x2, y2]

                        # Map v·ªõi CSV
                        matches = self.mapping_df[
                            self.mapping_df['SubClass'].str.lower() == class_name.lower()
                        ]

                        if not matches.empty:
                            row = matches.iloc[0]
                            detection = {
                                'box': xyxy,
                                'confidence': confidence,
                                'label': row['SubClass'],
                                'class_name': row['Class'],
                                'text': row['Text'],
                                'detected_subclass': class_name,
                                'mapped': True
                            }
                        else:
                            detection = {
                                'box': xyxy,
                                'confidence': confidence,
                                'label': class_name,
                                'class_name': None,
                                'text': None,
                                'detected_subclass': class_name,
                                'mapped': False
                            }

                        detections_data.append(detection)

        return detections_data

    def process_video_with_output(self, video_path, output_path=None,
                                top_k=5, top_n_classes=3, confidence_threshold=0.5,
                                fps_detect=1, max_duration=15,
                                output_fps=None, save_frames=False,
                                output_folder='video_frames'):
        """
        X·ª≠ l√Ω video, l∆∞u video k·∫øt qu·∫£ v·ªõi bounding box v√† t·ªïng h·ª£p th·ªëng k√™

        Args:
            video_path: ƒê∆∞·ªùng d·∫´n video input
            output_path: ƒê∆∞·ªùng d·∫´n video output (None = t·ª± ƒë·ªông t·∫°o)
            top_k: S·ªë l∆∞·ª£ng top objects (SubClass)
            top_n_classes: S·ªë l∆∞·ª£ng top Classes c√≥ nhi·ªÅu object nh·∫•t
            confidence_threshold: Ng∆∞·ª°ng confidence
            fps_detect: S·ªë frame/gi√¢y ƒë·ªÉ ch·∫°y detection (1 = detect m·ªói gi√¢y)
            max_duration: Th·ªùi l∆∞·ª£ng t·ªëi ƒëa x·ª≠ l√Ω (gi√¢y)
            output_fps: FPS c·ªßa video output (None = gi·ªØ nguy√™n FPS g·ªëc)
            save_frames: C√≥ l∆∞u frames ƒë√£ extract kh√¥ng
            output_folder: Th∆∞ m·ª•c l∆∞u frames

        Returns:
            dict: K·∫øt qu·∫£ t·ªïng h·ª£p
        """
        print(f"\n{'='*70}")
        print(f"üé• B·∫ÆT ƒê·∫¶U X·ª¨ L√ù VIDEO V·ªöI L∆ØU K·∫æT QU·∫¢")
        print(f"{'='*70}")
        print(f"üìπ Video: {os.path.basename(video_path)}")

        # ========== M·ªû VIDEO ==========
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print("‚ùå Kh√¥ng th·ªÉ m·ªü video!")
            return None

        # L·∫•y th√¥ng tin video
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        video_fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        duration = total_frames / video_fps

        print(f"\nüìä Th√¥ng tin video:")
        print(f"‚îú‚îÄ K√≠ch th∆∞·ªõc: {width}x{height}")
        print(f"‚îú‚îÄ FPS g·ªëc: {video_fps:.2f}")
        print(f"‚îú‚îÄ T·ªïng frames: {total_frames}")
        print(f"‚îî‚îÄ Th·ªùi l∆∞·ª£ng: {duration:.2f} gi√¢y")

        # Thi·∫øt l·∫≠p output
        if output_path is None:
            video_name = Path(video_path).stem
            output_path = f"{video_name}_detected.mp4"

        if output_fps is None:
            output_fps = video_fps

        # T·∫°o VideoWriter
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, output_fps, (width, height))

        print(f"\nüìπ Video output:")
        print(f"‚îú‚îÄ ƒê∆∞·ªùng d·∫´n: {output_path}")
        print(f"‚îú‚îÄ FPS: {output_fps:.2f}")
        print(f"‚îî‚îÄ Detect rate: {fps_detect} frame/gi√¢y")

        # T√≠nh to√°n
        process_duration = min(duration, max_duration)
        frame_interval = int(video_fps / fps_detect)
        total_process_frames = int(process_duration * video_fps)

        print(f"\n‚öôÔ∏è C·∫•u h√¨nh x·ª≠ l√Ω:")
        print(f"‚îú‚îÄ X·ª≠ l√Ω {process_duration:.2f}s / {duration:.2f}s")
        print(f"‚îú‚îÄ T·ªïng frames s·∫Ω x·ª≠ l√Ω: {total_process_frames}")
        print(f"‚îî‚îÄ Detection m·ªói {frame_interval} frames")

        # T·∫°o th∆∞ m·ª•c l∆∞u frames n·∫øu c·∫ßn
        if save_frames:
            os.makedirs(output_folder, exist_ok=True)

        # ========== X·ª¨ L√ù VIDEO ==========
        print(f"\n{'‚îÄ'*60}")
        print("üîÑ B·∫ÆT ƒê·∫¶U X·ª¨ L√ù")
        print(f"{'‚îÄ'*60}\n")

        all_detections = []
        frame_results = []
        current_detections = []  # L∆∞u detection hi·ªán t·∫°i ƒë·ªÉ √°p d·ª•ng cho frames gi·ªØa

        frame_count = 0
        detect_count = 0

        while frame_count < total_process_frames:
            ret, frame = cap.read()
            if not ret:
                break

            # Ki·ªÉm tra xem c√≥ c·∫ßn ch·∫°y detection kh√¥ng
            should_detect = (frame_count % frame_interval == 0)

            if should_detect:
                # Ch·∫°y detection
                current_detections = self.predict_and_map_with_boxes(
                    frame, confidence_threshold
                )
                detect_count += 1

                # L∆∞u k·∫øt qu·∫£
                time_stamp = frame_count / video_fps
                frame_results.append({
                    'frame': frame_count,
                    'time': time_stamp,
                    'detections': current_detections,
                    'count': len(current_detections)
                })

                # Th√™m v√†o all_detections
                all_detections.extend(current_detections)

                # In progress
                if detect_count % 5 == 0 or detect_count == 1:
                    print(f"‚è≥ ƒê√£ detect {detect_count} frames - "
                        f"T√¨m th·∫•y {len(current_detections)} objects t·∫°i {time_stamp:.1f}s")

                # L∆∞u frame n·∫øu c·∫ßn
                if save_frames:
                    frame_filename = f"frame_{detect_count:04d}_at_{time_stamp:.2f}s.jpg"
                    frame_path = os.path.join(output_folder, frame_filename)
                    cv2.imwrite(frame_path, frame)

            # V·∫Ω bounding box (s·ª≠ d·ª•ng detection g·∫ßn nh·∫•t)
            annotated_frame = self.draw_detections(frame, current_detections)

            # Th√™m th√¥ng tin timestamp
            timestamp_text = f"Time: {frame_count/video_fps:.2f}s | Objects: {len(current_detections)}"
            cv2.putText(
                annotated_frame,
                timestamp_text,
                (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.7,
                (255, 255, 255),
                2
            )

            # Ghi frame v√†o video output
            out.write(annotated_frame)

            frame_count += 1

        # ƒê√≥ng video
        cap.release()
        out.release()

        print(f"\n‚úÖ ƒê√£ x·ª≠ l√Ω {frame_count} frames")
        print(f"‚úÖ ƒê√£ ch·∫°y detection tr√™n {detect_count} frames")
        print(f"üíæ Video ƒë√£ l∆∞u: {output_path}")

        # ========== T·ªîNG H·ª¢P TH·ªêNG K√ä ==========
        print(f"\n{'‚îÄ'*60}")
        print("üìä T·ªîNG H·ª¢P K·∫æT QU·∫¢")
        print(f"{'‚îÄ'*60}")

        if all_detections:
            # ƒê·∫øm c√°c detection (ch·ªâ nh·ªØng c√°i ƒë√£ map)
            mapped_detections = [d for d in all_detections if d['mapped']]

            if mapped_detections:
                subclass_counter = Counter()
                class_counter = Counter()
                class_object_counter = Counter()  # ƒê·∫øm t·ªïng s·ªë object cho m·ªói Class
                confidence_dict = {}
                class_confidence_dict = {}  # L∆∞u confidence cho m·ªói Class

                for det in mapped_detections:
                    subclass = det['label']
                    main_class = det['class_name']

                    subclass_counter[subclass] += 1
                    class_counter[main_class] += 1
                    class_object_counter[main_class] += 1  # ƒê·∫øm m·ªói object thu·ªôc Class

                    # L∆∞u confidence cho SubClass
                    if subclass not in confidence_dict:
                        confidence_dict[subclass] = []
                    confidence_dict[subclass].append(det['confidence'])

                    # L∆∞u confidence cho Class
                    if main_class not in class_confidence_dict:
                        class_confidence_dict[main_class] = []
                    class_confidence_dict[main_class].append(det['confidence'])

                # T√≠nh confidence trung b√¨nh cho SubClass
                avg_confidence = {k: np.mean(v) for k, v in confidence_dict.items()}

                # T√≠nh confidence trung b√¨nh cho Class
                class_avg_confidence = {k: np.mean(v) for k, v in class_confidence_dict.items()}

                print(f"\nüìà Th·ªëng k√™ t·ªïng quan:")
                print(f"‚îú‚îÄ T·ªïng detections: {len(all_detections)}")
                print(f"‚îú‚îÄ ƒê√£ mapping: {len(mapped_detections)}")
                print(f"‚îú‚îÄ SubClass unique: {len(subclass_counter)}")
                print(f"‚îî‚îÄ Class unique: {len(class_counter)}")

                # ========== TOP K OBJECTS (SUBCLASS) ==========
                print(f"\n{'‚îÄ'*60}")
                print(f"üèÜ TOP {top_k} OBJECTS (SUBCLASS) XU·∫§T HI·ªÜN NHI·ªÄU NH·∫§T")
                print(f"{'‚îÄ'*60}")

                top_results = []
                for i, (subclass, count) in enumerate(subclass_counter.most_common(top_k), 1):
                    info = self.mapping_df[
                        self.mapping_df['SubClass'] == subclass
                    ].iloc[0]

                    frequency = (count / detect_count) * 100

                    result_item = {
                        'rank': i,
                        'subclass': subclass,
                        'class': info['Class'],
                        'text': info['Text'],
                        'appearances': count,
                        'total_detections': detect_count,
                        'frequency': frequency,
                        'avg_confidence': avg_confidence[subclass]
                    }

                    top_results.append(result_item)

                    print(f"\nü•á TOP {i}: {subclass}")
                    print(f"   ‚îú‚îÄ Class: {info['Class']}")
                    print(f"   ‚îú‚îÄ Xu·∫•t hi·ªán: {count}/{detect_count} frames ({frequency:.1f}%)")
                    print(f"   ‚îî‚îÄ Confidence TB: {avg_confidence[subclass]:.2%}")

                # ========== TOP N CLASSES C√ì NHI·ªÄU OBJECT NH·∫§T ==========
                print(f"\n{'‚îÄ'*60}")
                print(f"üèÜ TOP {top_n_classes} CLASSES C√ì NHI·ªÄU OBJECT NH·∫§T")
                print(f"{'‚îÄ'*60}")

                top_classes = []
                for i, (main_class, total_objects) in enumerate(class_object_counter.most_common(top_n_classes), 1):
                    # T√¨m c√°c SubClass thu·ªôc Class n√†y
                    subclasses_in_class = []
                    for subclass, count in subclass_counter.items():
                        info = self.mapping_df[
                            self.mapping_df['SubClass'] == subclass
                        ].iloc[0]
                        if info['Class'] == main_class:
                            subclasses_in_class.append({
                                'subclass': subclass,
                                'count': count
                            })

                    # S·∫Øp x·∫øp SubClass theo s·ªë l∆∞·ª£ng
                    subclasses_in_class.sort(key=lambda x: x['count'], reverse=True)

                    class_frequency = (total_objects / len(mapped_detections)) * 100

                    class_item = {
                        'rank': i,
                        'class': main_class,
                        'total_objects': total_objects,
                        'unique_subclasses': len(subclasses_in_class),
                        'subclasses': subclasses_in_class,
                        'frequency': class_frequency,
                        'avg_confidence': class_avg_confidence[main_class]
                    }

                    top_classes.append(class_item)

                    print(f"\nüèÖ TOP {i}: {main_class}")
                    print(f"   ‚îú‚îÄ T·ªïng s·ªë objects: {total_objects}")
                    print(f"   ‚îú‚îÄ T·ª∑ l·ªá: {class_frequency:.1f}% trong t·ªïng s·ªë detections")
                    print(f"   ‚îú‚îÄ S·ªë SubClass kh√°c nhau: {len(subclasses_in_class)}")
                    print(f"   ‚îú‚îÄ Confidence TB: {class_avg_confidence[main_class]:.2%}")
                    print(f"   ‚îî‚îÄ Chi ti·∫øt SubClass:")

                    # Hi·ªÉn th·ªã top 3 SubClass c·ªßa Class n√†y
                    for j, sub_item in enumerate(subclasses_in_class[:3], 1):
                        print(f"       {j}. {sub_item['subclass']}: {sub_item['count']} objects")

                    if len(subclasses_in_class) > 3:
                        print(f"       ... v√† {len(subclasses_in_class) - 3} SubClass kh√°c")

                # ========== TH·ªêNG K√ä THEO TH·ªúI GIAN ==========
                print(f"\n{'‚îÄ'*60}")
                print("üìà PH√ÇN B·ªê THEO TH·ªúI GIAN")
                print(f"{'‚îÄ'*60}")

                # Chia video th√†nh c√°c kho·∫£ng th·ªùi gian
                time_segments = 5  # Chia th√†nh 5 ph·∫ßn
                segment_duration = process_duration / time_segments

                time_distribution = []
                for seg in range(time_segments):
                    start_time = seg * segment_duration
                    end_time = (seg + 1) * segment_duration

                    # ƒê·∫øm detections trong kho·∫£ng th·ªùi gian n√†y
                    segment_detections = 0
                    for frame_result in frame_results:
                        if start_time <= frame_result['time'] < end_time:
                            segment_detections += frame_result['count']

                    time_distribution.append({
                        'segment': seg + 1,
                        'start': start_time,
                        'end': end_time,
                        'detections': segment_detections
                    })

                    print(f"   Ph√∫t {start_time:.1f}-{end_time:.1f}s: {segment_detections} objects")

                # T·∫°o summary ƒë·∫ßy ƒë·ªß
                summary = {
                    'video_info': {
                        'input_path': video_path,
                        'output_path': output_path,
                        'duration': duration,
                        'processed_duration': process_duration,
                        'total_frames': frame_count,
                        'detected_frames': detect_count,
                        'resolution': f"{width}x{height}",
                        'fps': video_fps,
                        'output_fps': output_fps
                    },
                    'detection_summary': {
                        'total_detections': len(all_detections),
                        'mapped_detections': len(mapped_detections),
                        'unique_subclasses': len(subclass_counter),
                        'unique_classes': len(class_counter)
                    },
                    'top_objects': top_results,  # Top k objects (SubClass)
                    'top_classes': top_classes,  # Top n Classes c√≥ nhi·ªÅu object nh·∫•t
                    'time_distribution': time_distribution,
                    'frame_details': frame_results,
                    'yolo_detections': all_detections

                }

                print(f"\n{'='*70}")
                print("‚úÖ HO√ÄN TH√ÄNH!")
                print(f"{'='*70}")

                return summary

        print("\n‚ùå Kh√¥ng ph√°t hi·ªán object n√†o!")
        return None

#ƒê·∫øm s·ªë ƒë·ªëi t∆∞·ª£ng trong 1 frame

# Kh·ªüi t·∫°o pipeline
pipeline = YOLOCSVPipeline(
    model_path=model_path,
    csv_path=csv_path
)

# X·ª≠ l√Ω video v√† l∆∞u k·∫øt qu·∫£
result = pipeline.process_video_with_output(
    video_path=video_path,
    output_path=output_video_path,  # None = t·ª± ƒë·ªông t·∫°o t√™n
    confidence_threshold=0.5,
    fps_detect=1,  # Detect 1 frame/gi√¢y
    max_duration=30,  # X·ª≠ l√Ω t·ªëi ƒëa 30 gi√¢y
    output_fps=None,  # None = gi·ªØ nguy√™n FPS g·ªëc
    save_frames=True,  # L∆∞u c√°c frame ƒë√£ detect
    output_folder='detected_frames',
    top_k=10
)

# ƒê·ªãnh nghƒ©a c·∫•u tr√∫c d·ªØ li·ªáu
class ObjectDetection:
    def __init__(self, subclass, confidence, frame_id, time_stamp, count, bboxs):
        self.subclass = subclass          # e.g., "binh_bong_dua"
        self.confidence = confidence      # trung b√¨nh c√°c confidence trong frame
        self.frame_id = frame_id          # s·ªë th·ª© t·ª± frame
        self.time_stamp = time_stamp      # th·ªùi gian (gi√¢y)
        self.count = count        # s·ªë l·∫ßn subclass xu·∫•t hi·ªán trong frame
        self.bboxs = bboxs                # danh s√°ch bounding box (list of [x1, y1, x2, y2])
    def __repr__(self):
        return (f"ObjectDetection(subclass='{self.subclass}', "
                f"confidence={self.confidence:.2f}, "
                f"frame_id={self.frame_id}, "
                f"time_stamp={self.time_stamp:.2f}, "
                f"count={self.count}, "
                f"bboxs={self.bboxs})")

# Database r√†ng bu·ªôc: dict[l·ªÖ_h·ªôi] = list[r√†ng_bu·ªôc]
# M·ªói r√†ng_bu·ªôc l√† tuple (type, params, is_hard, weight, threshold)
# V√≠ d·ª•: ("is_presence", ["binh_bong_dua", "hoa_sen"], True, 1.0, None)  # Hard, ph·∫£i c√≥ c·∫£ hai
# ("at_least", ["binh_bong_dua"], True, 1.0, 10)  # Hard, √≠t nh·∫•t 10 instances
# ("is_on", ["bong_dua", "trai_dua"], False, 0.5, None)  # Soft, weight 0.5 n·∫øu "bong_dua" on "trai_dua" (c√≥ th·ªÉ d√πng spatial check)
# ("confidence_min", ["all"], True, 1.0, 0.7)  # Hard, avg confidence >=0.7

# Chuy·ªÉn ƒë·ªïi k·∫øt qu·∫£ c·ªßa h√†m d·ª± ƒëo√°n th√†nh list ƒë·ªëi t∆∞·ª£ng
summary = result

object_detections = []  # danh s√°ch ObjectDetection

for frame_data in summary['frame_details']:
    frame_id = frame_data['frame']
    time_stamp = frame_data['time']
    detections = frame_data['detections']

    # Gom nh√≥m detection theo subclass (label)
    subclass_groups = {}
    for det in detections:
        if det['mapped']:
            subclass = det['label']
            if subclass not in subclass_groups:
                subclass_groups[subclass] = {'confidences': [], 'bboxs': []}
            subclass_groups[subclass]['confidences'].append(det['confidence'])
            subclass_groups[subclass]['bboxs'].append(det['box'].tolist())  # numpy ‚Üí list

    # T·∫°o ObjectDetection cho m·ªói subclass trong frame
    for subclass, data in subclass_groups.items():
        avg_conf = np.mean(data['confidences']) if data['confidences'] else 0.0
        count = len(data['bboxs'])  # s·ªë l·∫ßn subclass xu·∫•t hi·ªán trong frame

        obj = ObjectDetection(
            subclass=subclass,
            confidence=avg_conf,
            frame_id=frame_id,
            time_stamp=time_stamp,
            count=count,
            bboxs=data['bboxs']  # danh s√°ch bounding boxes
        )
        object_detections.append(obj)

print(f"‚úÖ ƒê√£ t·∫°o {len(object_detections)} ƒë·ªëi t∆∞·ª£ng ObjectDetection (c√≥ bboxs).")

def check_constraints(detections, CONSTRAINTS_DB, SUBCLASS_TO_FESTIVAL=None, score_threshold=0.7):
    """
    H√†m ki·ªÉm tra r√†ng bu·ªôc (Logic ƒë√£ tinh ch·ªânh).

    Args:
        detections: List[ObjectDetection] - Output t·ª´ YOLO sau khi qua x·ª≠ l√Ω
        CONSTRAINTS_DB: Dict - C∆° s·ªü d·ªØ li·ªáu lu·∫≠t
        SUBCLASS_TO_FESTIVAL: Dict (Optional) - D√πng ƒë·ªÉ l·ªçc nhanh ·ª©ng vi√™n
        score_threshold: Float - Ng∆∞·ª°ng ƒëi·ªÉm ƒë·ªÉ ch·∫•p nh·∫≠n k·∫øt qu·∫£

    Returns:
        Dict: C·∫•u tr√∫c k·∫øt qu·∫£ gi·ªØ nguy√™n nh∆∞ c≈©.
    """

    # --- 1. Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu (Indexing) ---
    # Gom nh√≥m ƒë·ªÉ truy xu·∫•t nhanh O(1) thay v√¨ loop nhi·ªÅu l·∫ßn
    detections_by_subclass = defaultdict(list)
    detections_by_frame = defaultdict(list)

    for det in detections:
        # Ch·ªâ x√©t c√°c object c√≥ mapping h·ª£p l·ªá
        detections_by_subclass[det.subclass].append(det)
        detections_by_frame[det.frame_id].append(det)

    # H√†m ph·ª• ki·ªÉm tra v·ªã tr√≠ (IS_ON)
    def check_is_on_logic(top_subclass, bottom_subclass):
        # Duy·ªát qua c√°c frame c√≥ xu·∫•t hi·ªán c·∫£ 2 lo·∫°i object
        relevant_frames = set(d.frame_id for d in detections_by_subclass[top_subclass]) & \
                        set(d.frame_id for d in detections_by_subclass[bottom_subclass])

        for fid in relevant_frames:
            tops = [d for d in detections_by_frame[fid] if d.subclass == top_subclass]
            bottoms = [d for d in detections_by_frame[fid] if d.subclass == bottom_subclass]

            for t in tops:
                for b in bottoms:
                    for box_t in t.bboxs: # box_t: [x1, y1, x2, y2]
                        for box_b in b.bboxs:
                            # Ki·ªÉm tra overlap tr·ª•c X (ngang)
                            x_overlap = max(0, min(box_t[2], box_b[2]) - max(box_t[0], box_b[0]))
                            width_t = box_t[2] - box_t[0]

                            # Ki·ªÉm tra tr·ª•c Y: ƒê√°y c·ªßa Top ph·∫£i n·∫±m g·∫ßn ƒê·ªânh c·ªßa Bottom
                            # box[1]=y1 (top), box[3]=y2 (bottom) - Gi·∫£ s·ª≠ tr·ª•c y h∆∞·ªõng xu·ªëng
                            vertical_gap = box_b[1] - box_t[3]

                            # Logic: Overlap ngang > 30% width v·∫≠t tr√™n V√Ä kho·∫£ng c√°ch d·ªçc < 20px
                            if width_t > 0 and (x_overlap / width_t) > 0.3 and -50 <= vertical_gap <= 50:
                                return True
        return False

    # --- 2. L·ªçc ·ª©ng vi√™n (Candidate Filtering) ---
    if SUBCLASS_TO_FESTIVAL:
        detected_subclasses = set(detections_by_subclass.keys())
        candidate_festivals = set()
        for sub in detected_subclasses:
            if sub in SUBCLASS_TO_FESTIVAL:
                candidate_festivals.update(SUBCLASS_TO_FESTIVAL[sub])

        if not candidate_festivals:
            candidate_festivals = set(CONSTRAINTS_DB.keys())
    else:
        candidate_festivals = set(CONSTRAINTS_DB.keys())

    # --- 3. ƒê√°nh gi√° t·ª´ng l·ªÖ h·ªôi ---
    festival_results = {}

    for festival in candidate_festivals:
        # N·∫øu l·ªÖ h·ªôi kh√¥ng c√≥ trong DB lu·∫≠t th√¨ b·ªè qua
        if festival not in CONSTRAINTS_DB:
            continue

        constraints = CONSTRAINTS_DB[festival]
        total_weight_achieved = 0.0
        total_weight_possible = 0.0
        hard_failed = False

        # L∆∞u chi ti·∫øt t·ª´ng lu·∫≠t ƒë·ªÉ debug/gi·∫£i th√≠ch
        rule_details = []

        for (ctype, params, is_hard, weight, threshold) in constraints:
            satisfied = False
            current_val = 0 # Gi√° tr·ªã th·ª±c t·∫ø ƒëo ƒë∆∞·ª£c (ƒë·ªÉ so s√°nh v·ªõi threshold)

            # --- LOGIC T·ª™NG LO·∫†I R√ÄNG BU·ªòC ---

            # 1. IS_PRESENCE: C√≥ xu·∫•t hi·ªán trong video kh√¥ng?
            if ctype == "is_presence":
                # Logic: T·∫•t c·∫£ params ph·∫£i c√≥ m·∫∑t
                missing_params = [p for p in params if p not in detections_by_subclass]
                satisfied = len(missing_params) == 0

            # 2. IS_PRESENCE_IN_FRAME: C√πng xu·∫•t hi·ªán trong 1 frame
            elif ctype == "is_presence_in_frame":
                # Logic: T√¨m xem c√≥ frame n√†o ch·ª©a ƒë·ªß t·∫•t c·∫£ params kh√¥ng
                for fid, dets in detections_by_frame.items():
                    subs_in_frame = {d.subclass for d in dets}
                    if all(p in subs_in_frame for p in params):
                        satisfied = True
                        break

            # 3. AT_LEAST: T·ªïng s·ªë l∆∞·ª£ng (C·ªông d·ªìn count) >= Threshold
            elif ctype == "at_least":
                # Logic: T·ªïng count c·ªßa t·∫•t c·∫£ params >= threshold
                total_count = 0
                for p in params:
                    if p in detections_by_subclass:
                        total_count += sum(d.count for d in detections_by_subclass[p])
                current_val = total_count
                satisfied = total_count >= (threshold or 1)

            # 4. AT_LEAST_IN_FRAME: (Gi·ªØ nguy√™n logic c≈© ho·∫∑c hi·ªÉu l√† xu·∫•t hi·ªán c√πng nhau >= N l·∫ßn)
            # Theo code c≈© c·ªßa b·∫°n: Check xem c√≥ frame n√†o ch·ª©a ƒë·ªß params v√† count >= threshold
            elif ctype == "at_least_in_frame":
                for fid, dets in detections_by_frame.items():
                    subs_in_frame = {d.subclass for d in dets}
                    # Check ƒë·ªß lo·∫°i
                    if all(p in subs_in_frame for p in params):
                        # Check ƒë·ªß l∆∞·ª£ng (t·ªïng l∆∞·ª£ng c·ªßa c√°c params trong frame n√†y)
                        frame_count = sum(d.count for d in dets if d.subclass in params)
                        if frame_count >= (threshold or 1):
                            satisfied = True
                            break

            # 5. CONFIDENCE_MIN: ƒê·ªô tin c·∫≠y trung b√¨nh >= Threshold
            elif ctype == "confidence_min":
                target_subs = []
                if "all" in params:
                    target_subs = list(detections_by_subclass.keys())
                else:
                    target_subs = [p for p in params if p in detections_by_subclass]

                if target_subs:
                    # T√≠nh trung b√¨nh c√≥ tr·ªçng s·ªë (weighted by count)
                    total_conf = 0
                    total_cnt = 0
                    for sub in target_subs:
                        for d in detections_by_subclass[sub]:
                            total_conf += d.confidence * d.count
                            total_cnt += d.count

                    avg_conf = total_conf / total_cnt if total_cnt > 0 else 0
                    current_val = avg_conf
                    satisfied = avg_conf >= (threshold or 0)
                else:
                    satisfied = False # Kh√¥ng t√¨m th·∫•y ƒë·ªëi t∆∞·ª£ng ƒë·ªÉ check confidence

            # 6. IS_ON: V·ªã tr√≠ t∆∞∆°ng ƒë·ªëi
            elif ctype == "is_on" and len(params) == 2:
                satisfied = check_is_on_logic(params[0], params[1])

            # --- T√çNH ƒêI·ªÇM ---
            total_weight_possible += weight

            if satisfied:
                total_weight_achieved += weight
            elif is_hard:
                hard_failed = True

            # L∆∞u log (n·∫øu c·∫ßn m·ªü r·ªông sau n√†y)
            # rule_details.append({"type": ctype, "satisfied": satisfied, "hard": is_hard})

        # --- T·ªîNG H·ª¢P K·∫æT QU·∫¢ CHO L·ªÑ H·ªòI ---

        # ƒêi·ªÉm chu·∫©n h√≥a (Normalized Score): Lu√¥n t·ª´ 0.0 ƒë·∫øn 1.0
        normalized_score = 0.0
        if total_weight_possible > 0:
            normalized_score = total_weight_achieved / total_weight_possible

        festival_results[festival] = {
            "score": total_weight_achieved,      # ƒêi·ªÉm th√¥ (User mu·ªën xem c·ªông d·ªìn)
            "normalized_score": normalized_score, # ƒêi·ªÉm d√πng ƒë·ªÉ so s√°nh (ƒë√£ chia t·ªïng)
            "hard_failed": hard_failed,
            "satisfied": (not hard_failed) and (normalized_score >= score_threshold)
        }

    # --- 4. Ch·ªçn k·∫øt qu·∫£ t·ªët nh·∫•t ---
    # L·ªçc ra c√°c l·ªÖ h·ªôi th·ªèa m√£n ƒëi·ªÅu ki·ªán
    valid_festivals = {
        f: r["normalized_score"]
        for f, r in festival_results.items()
        if r["satisfied"]
    }

    if valid_festivals:
        # Ch·ªçn l·ªÖ h·ªôi c√≥ ƒëi·ªÉm chu·∫©n h√≥a cao nh·∫•t
        best_festival = max(valid_festivals, key=valid_festivals.get)
        return {
            "festival": best_festival,
            "score": valid_festivals[best_festival],
            "details": festival_results
        }
    else:
        # Fallback: N·∫øu kh√¥ng ai ƒë·∫°t threshold, tr·∫£ v·ªÅ None ho·∫∑c ng∆∞·ªùi c√≥ ƒëi·ªÉm cao nh·∫•t (nh∆∞ng satisfied=False)
        return {
            "festival": None,
            "score": 0.0,
            "details": festival_results
        }
from constraintsDB import CONSTRAINTS_DB, SUBCLASS_TO_FESTIVAL
check_constraints(object_detections, CONSTRAINTS_DB, SUBCLASS_TO_FESTIVAL, score_threshold=0.7)