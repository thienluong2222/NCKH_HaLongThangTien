import streamlit as st
import numpy as np
import json
import os
from collections import defaultdict
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_community.document_loaders import TextLoader
from langchain_core.output_parsers import StrOutputParser

# ==========================================
# PHáº¦N 1: Cáº¤U TRÃšC Dá»® LIá»†U & RÃ€NG BUá»˜C (CSP)
# ==========================================

class ObjectDetection:
    """Cáº¥u trÃºc dá»¯ liá»‡u Ä‘áº¡i diá»‡n cho má»™t Ä‘á»‘i tÆ°á»£ng Ä‘Æ°á»£c phÃ¡t hiá»‡n (hoáº·c ngÆ°á»i dÃ¹ng thÃªm vÃ o)"""
    def __init__(self, subclass, confidence, frame_id, count, is_virtual=False):
        self.subclass = subclass
        self.confidence = confidence
        self.frame_id = frame_id
        self.count = count
        self.is_virtual = is_virtual  # True náº¿u do ngÆ°á»i dÃ¹ng xÃ¡c nháº­n, False náº¿u do YOLO detect

# Database RÃ ng buá»™c (TrÃ­ch xuáº¥t tá»« Colab cá»§a báº¡n)
CONSTRAINTS_DB = {
    "Lá»… há»™i Ooc Bom BÃ³c": [
        ("confidence_min", ["Ghe ngo"], True, 1.0, 0.7),
        ("is_presence", ["Den hoa dang", "Den nuoc"], True, 1.0, None),
        ("at_least", ["Den troi"], False, 0.5, 1),
        ("at_least", ["Com", "Khoai"], False, 0.6, None)
    ],
    "Táº¿t Choi Chnam Thmay": [
        ("confidence_min", ["Nui cat"], True, 1.0, 0.8),
        ("at_least", ["Nguoi tham gia te nuoc", "Nuoc thom"], False, 0.8, None),
        ("is_presence", ["Tuong Phat", "Nha su"], True, 1.0, None)
    ],
    "Chá»£ ná»•i CÃ¡i RÄƒng": [
        ("is_presence", ["Cay beo", "Thuyen"], True, 1.0, None),
        ("is_on", ["Cay beo", "Thuyen"], True, 1.0, None)
    ]
}

# Danh sÃ¡ch táº¥t cáº£ cÃ¡c subclass há»‡ thá»‘ng biáº¿t
ALL_SUBCLASSES = [
    "Ghe ngo", "Den hoa dang", "Den nuoc", "Den troi", "Com", "Khoai",
    "Nui cat", "Nguoi tham gia te nuoc", "Nuoc thom", "Tuong Phat", "Nha su",
    "Cay beo", "Thuyen"
]

def check_constraints(detections, constraints_db, score_threshold=0.50):
    """
    HÃ m kiá»ƒm tra xem danh sÃ¡ch detections hiá»‡n táº¡i khá»›p vá»›i lá»… há»™i nÃ o nháº¥t.
    """
    detections_by_subclass = defaultdict(list)
    for det in detections:
        detections_by_subclass[det.subclass].append(det)

    festival_results = {}

    for festival, constraints in constraints_db.items():
        total_score = 0.0
        max_score = 0.0
        hard_failed = False
        missing_rules = []

        for constraint in constraints:
            ctype, params, is_hard, weight, threshold = constraint
            satisfied = False

            if ctype == "is_presence" or ctype == "is_presence_in_frame":
                satisfied = all(sub in detections_by_subclass for sub in params)
            elif ctype == "at_least" or ctype == "at_least_in_frame":
                satisfied = all(sub in detections_by_subclass for sub in params)
            elif ctype == "confidence_min":
                target = params[0]
                if target in detections_by_subclass:
                    confs = [d.confidence for d in detections_by_subclass[target]]
                    avg_conf = np.mean(confs)
                    satisfied = avg_conf >= threshold
                else:
                    satisfied = False
            elif ctype == "is_on":
                satisfied = all(sub in detections_by_subclass for sub in params)

            if satisfied:
                total_score += weight
            else:
                missing_rules.append((ctype, params))
                if is_hard:
                    hard_failed = True
            
            max_score += weight

        normalized_score = total_score / max_score if max_score > 0 else 0.0
        final_valid_score = 0.0 if hard_failed else normalized_score

        festival_results[festival] = {
            "score": final_valid_score,
            "potential_score": normalized_score,
            "missing": missing_rules,
            "hard_failed": hard_failed
        }

    best_candidate = max(festival_results, key=lambda k: festival_results[k]['potential_score'])
    
    return {
        "best_candidate": best_candidate,
        "current_score": festival_results[best_candidate]['score'],
        "potential_score": festival_results[best_candidate]['potential_score'],
        "details": festival_results
    }

# ==========================================
# PHáº¦N 2: TRÃ TUá»† NHÃ‚N Táº O (LLM FUNCTIONS - ÄÃƒ Sá»¬A Lá»–I)
# ==========================================

def load_knowledge():
    if os.path.exists("text_data.txt"):
        loader = TextLoader("text_data.txt", encoding='utf-8')
        return loader.load()[0].page_content
    return ""

def generate_verification_question(candidate, missing_rule, knowledge_text, api_key):
    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", google_api_key=api_key)
    
    ctype, params = missing_rule
    missing_objects = ", ".join(params)
    
    prompt_template = """
    Báº¡n lÃ  má»™t thÃ¡m tá»­ AI. Báº¡n Ä‘ang nghi ngá» video nÃ y lÃ  vá» lá»… há»™i: "{candidate}".
    Tuy nhiÃªn, há»‡ thá»‘ng mÃ¡y tÃ­nh chÆ°a tÃ¬m tháº¥y hÃ¬nh áº£nh cá»§a: {missing_objects}.
    
    Sá»­ dá»¥ng kiáº¿n thá»©c sau Ä‘Ã¢y:
    {context}
    
    HÃ£y Ä‘áº·t má»™t cÃ¢u há»i ngáº¯n gá»n, lá»‹ch sá»± cho ngÆ°á»i dÃ¹ng Ä‘á»ƒ xÃ¡c nháº­n xem há» cÃ³ nhÃ¬n tháº¥y váº­t thá»ƒ Ä‘Ã³ trong video khÃ´ng.
    VÃ­ dá»¥: "Báº¡n cÃ³ tháº¥y chiáº¿c ghe ngo (thuyá»n dÃ i) nÃ o xuáº¥t hiá»‡n khÃ´ng?"
    Chá»‰ in ra cÃ¢u há»i.
    """
    
    prompt = ChatPromptTemplate.from_template(prompt_template)
    
    # Táº¡o chain: Prompt -> LLM -> String Output
    chain = prompt | llm | StrOutputParser()
    
    response = chain.invoke({
        "candidate": candidate,
        "missing_objects": missing_objects,
        "context": knowledge_text
    })
    return response

def analyze_user_answer(user_text, expected_objects, api_key):

    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", google_api_key=api_key, temperature=0)
    
    prompt_template = """
    Há»‡ thá»‘ng Ä‘ang há»i ngÆ°á»i dÃ¹ng vá» viá»‡c há» cÃ³ tháº¥y cÃ¡c váº­t thá»ƒ sau khÃ´ng: {expected_objects}.
    NgÆ°á»i dÃ¹ng tráº£ lá»i: "{user_text}".
    Danh sÃ¡ch cÃ¡c ID váº­t thá»ƒ há»£p lá»‡ trong há»‡ thá»‘ng: {all_subclasses}.
    
    HÃ£y phÃ¢n tÃ­ch cÃ¢u tráº£ lá»i:
    1. NgÆ°á»i dÃ¹ng cÃ³ xÃ¡c nháº­n (YES) lÃ  nhÃ¬n tháº¥y khÃ´ng?
    2. Náº¿u cÃ³, há» Ä‘ang nÃ³i vá» váº­t thá»ƒ nÃ o trong danh sÃ¡ch ID há»£p lá»‡?
    
    Tráº£ vá» káº¿t quáº£ dÆ°á»›i dáº¡ng JSON KHÃ”NG CÃ“ Markdown:
    {{
        "is_confirmed": true/false,
        "detected_object_id": "Ten_Subclass_Hoac_Null"
    }}
    """
    
    prompt = ChatPromptTemplate.from_template(prompt_template)
    
    # Táº¡o chain
    chain = prompt | llm | StrOutputParser()
    
    response_str = chain.invoke({
        "expected_objects": ", ".join(expected_objects),
        "user_text": user_text,
        "all_subclasses": ", ".join(ALL_SUBCLASSES)
    })
    
    # Xá»­ lÃ½ JSON
    try:
        content = response_str.strip().replace("```json", "").replace("```", "")
        return json.loads(content)
    except:
        return {"is_confirmed": False, "detected_object_id": None}

# ==========================================
# PHáº¦N 3: GIAO DIá»†N STREAMLIT
# ==========================================

st.set_page_config(page_title="AI Human-in-the-loop Chatbot", page_icon="ğŸ•µï¸")

st.title("ğŸ•µï¸ Há»‡ thá»‘ng xÃ¡c thá»±c Lá»… há»™i thÃ´ng minh")
st.markdown("---")

# --- Sidebar ---
with st.sidebar:
    st.header("Cáº¥u hÃ¬nh")
    api_key = st.text_input("Nháº­p Gemini API Key", type="default", value="AIzaSyAyAxK7QfgwcETsoLZ3iB4SbUYP0gTGSCg")
    
    if st.button("ğŸ”„ Reset dá»¯ liá»‡u giáº£ láº­p"):
        st.session_state.clear()
        st.rerun()
    
    st.markdown("---")
    st.markdown("**Tráº¡ng thÃ¡i hiá»‡n táº¡i:**")
    if "detections" in st.session_state:
        st.write(f"Sá»‘ lÆ°á»£ng váº­t thá»ƒ: {len(st.session_state.detections)}")
        for det in st.session_state.detections:
            icon = "ğŸ‘¤" if det.is_virtual else "ğŸ“·"
            st.code(f"{icon} {det.subclass} ({det.confidence:.1f})")

# --- Khá»Ÿi táº¡o dá»¯ liá»‡u ---
if "detections" not in st.session_state:
    st.session_state.detections = [
        ObjectDetection("Den nuoc", 0.95, 1, 1),
        ObjectDetection("Com", 0.75, 5, 1)
    ]
    st.session_state.chat_history = []
    st.session_state.finished = False
    
    initial_msg = "ChÃ o báº¡n! TÃ´i Ä‘Ã£ phÃ¢n tÃ­ch video. TÃ´i tháº¥y cÃ³ **ÄÃ¨n nÆ°á»›c** vÃ  **Cá»‘m**. Tuy nhiÃªn, tÃ´i chÆ°a cháº¯c cháº¯n Ä‘Ã¢y lÃ  lá»… há»™i gÃ¬."
    st.session_state.chat_history.append({"role": "assistant", "content": initial_msg})

# --- Hiá»ƒn thá»‹ lá»‹ch sá»­ chat ---
for msg in st.session_state.chat_history:
    st.chat_message(msg["role"]).write(msg["content"])

# --- Main Logic Loop ---
if not st.session_state.finished and api_key:
    
    result = check_constraints(st.session_state.detections, CONSTRAINTS_DB)
    best_cand = result["best_candidate"]
    curr_score = result["current_score"]
    missing = result["details"][best_cand]["missing"]
    
    if curr_score >= 0.85:
        success_msg = f"ğŸ‰ **Káº¾T LUáº¬N:** Dá»±a trÃªn cÃ¡c báº±ng chá»©ng (cáº£ tá»« camera vÃ  xÃ¡c nháº­n cá»§a báº¡n), tÃ´i kháº³ng Ä‘á»‹nh Ä‘Ã¢y lÃ  **{best_cand}** (Äá»™ tin cáº­y: {curr_score:.0%})."
        if st.session_state.chat_history[-1]["content"] != success_msg:
            st.chat_message("assistant").write(success_msg)
            st.session_state.chat_history.append({"role": "assistant", "content": success_msg})
            st.session_state.finished = True
            st.balloons()
            st.rerun()
    
    else:
        last_role = st.session_state.chat_history[-1]["role"]
        
        if last_role == "user" or len(st.session_state.chat_history) == 1:
            if not missing:
                warn_msg = "KhÃ´ng cÃ²n manh má»‘i nÃ o Ä‘á»ƒ há»i, nhÆ°ng Ä‘á»™ tin cáº­y váº«n tháº¥p."
                if st.session_state.chat_history[-1]["content"] != warn_msg:
                    st.warning(warn_msg)
                    st.session_state.finished = True
            else:
                missing_rule = missing[0]
                missing_params = missing_rule[1]
                
                with st.spinner("Äang suy luáº­n cÃ¢u há»i tiáº¿p theo..."):
                    knowledge = load_knowledge()
                    question = generate_verification_question(best_cand, missing_rule, knowledge, api_key)
                
                st.chat_message("assistant").write(question)
                st.session_state.chat_history.append({"role": "assistant", "content": question})
                st.session_state.pending_check = missing_params

# --- Input Box ---
if not st.session_state.finished:
    if prompt := st.chat_input("Nháº­p cÃ¢u tráº£ lá»i cá»§a báº¡n..."):
        st.chat_message("user").write(prompt)
        st.session_state.chat_history.append({"role": "user", "content": prompt})
        
        if "pending_check" in st.session_state and api_key:
            with st.spinner("Äang phÃ¢n tÃ­ch cÃ¢u tráº£ lá»i..."):
                analysis = analyze_user_answer(prompt, st.session_state.pending_check, api_key)
                
                if analysis["is_confirmed"] and analysis["detected_object_id"]:
                    obj_id = analysis["detected_object_id"]
                    new_obj = ObjectDetection(subclass=obj_id, confidence=1.0, frame_id=-1, count=1, is_virtual=True)
                    st.session_state.detections.append(new_obj)
                    st.caption(f"âœ… *ÄÃ£ ghi nháº­n báº±ng chá»©ng má»›i:* **{obj_id}**")
                else:
                    st.caption("ÄÃ£ ghi nháº­n pháº£n há»“i (KhÃ´ng tÃ¬m tháº¥y báº±ng chá»©ng má»›i).")
                
                st.session_state.pop("pending_check", None)
                st.rerun()
        else:
            if not api_key:
                st.error("Vui lÃ²ng nháº­p API Key Ä‘á»ƒ tiáº¿p tá»¥c.")